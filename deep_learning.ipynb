{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fractor16/Project1/blob/master/deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUZooKfS2HYT",
        "outputId": "c8e12175-fbac-4d60-e64b-e36006c14b91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 41.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 6.8 MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.set_project('deep-learning')\n",
        "jovian.set_colab_id('1yZq8u7ZKokjZijSc1t7sIrVnWE0nGdv6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY36_OjC2HYW"
      },
      "source": [
        "# deep-learning\n",
        "\n",
        "Use the \"Run\" button to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LewW8Vc2HYX"
      },
      "outputs": [],
      "source": [
        "!pip install jovian --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugg9EIOE2HYX"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "9kXps4vG2HYY",
        "outputId": "7e87ae69-847c-49b1-d71a-840efb62cdbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "Committed successfully! https://jovian.ai/piyushbisht661/deep-learning\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/piyushbisht661/deep-learning'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute this to save new versions of the notebook\n",
        "jovian.commit(project=\"deep-learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDdU21hrBmCY"
      },
      "source": [
        "## TODO\n",
        "1. Pick a datset\n",
        "2. Download the dataset\n",
        "3. Import the datset using PyTorch\n",
        "4. Explore the datset\n",
        "5. Prepare the dataset for training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L09JjWt92HYY",
        "outputId": "90e8586e-dc33-4a10-f40b-e77242bbd40a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.5.18.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2C34ZUwxkif"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfhG02Uyxo3l"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://www.kaggle.com/alxmamaev/flowers-recognition'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vprq_cF6xqzi",
        "outputId": "10a3a28b-061c-48d3-e898-0c03c4d45b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: piyumshbisht\n",
            "Your Kaggle Key: ··········\n",
            "Downloading flowers-recognition.zip to ./flowers-recognition\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 225M/225M [00:01<00:00, 153MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7C--FKhySKd"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu5IXBCtxxXB"
      },
      "outputs": [],
      "source": [
        "data_dir = './flowers-recognition/flowers'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4WAiqSEyLrA",
        "outputId": "492371d1-0a0e-4e59-a7e5-25592d7a610b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tulip', 'rose', 'daisy', 'sunflower', 'dandelion']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLT94sgGyNCm",
        "outputId": "13ae16b2-4c40-4f6c-87d5-62e522dfe467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tulip : 984\n",
            "rose : 784\n",
            "daisy : 764\n",
            "sunflower : 733\n",
            "dandelion : 1052\n"
          ]
        }
      ],
      "source": [
        "for cls in os.listdir(data_dir):\n",
        "    print(cls, ':', len(os.listdir(data_dir + '/' + cls)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78t7L3D4ydsC"
      },
      "outputs": [],
      "source": [
        "!pip install jovian --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIuWrSzxylE3"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mckw_cjtynLl"
      },
      "outputs": [],
      "source": [
        "jovian.commit(project='deep-learning-project-live')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26OXDoKPyxd9"
      },
      "source": [
        "### Import the dataset into pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL48wZL3ypc_"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmPRsjspy4pq"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vE5Ju-Hy6hd"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CxkcyAwy8oV"
      },
      "outputs": [],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2b3NhD4y9pR"
      },
      "outputs": [],
      "source": [
        "dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8gI9WOJy-15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChCpkborzAhX"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[120]\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv1Mi9NjzCD2"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as tt\n",
        "\n",
        "dataset = ImageFolder(data_dir, tt.Compose([tt.Resize(64), \n",
        "                                            tt.RandomCrop(64), \n",
        "                                            tt.ToTensor()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucAkaA2GzDj-"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[120]\n",
        "plt.imshow(img.permute((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrp_axNhzFKt"
      },
      "outputs": [],
      "source": [
        "val_pct = 0.1\n",
        "val_size = int(val_pct * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_size, val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suFBq36YzabF"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, valid_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afTcQADa1Enx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_dl = DataLoader(train_ds, \n",
        "                      batch_size, \n",
        "                      shuffle=True, \n",
        "                      num_workers=4, \n",
        "                      pin_memory=True)\n",
        "\n",
        "valid_dl = DataLoader(valid_ds, \n",
        "                    batch_size, \n",
        "                    num_workers=4, \n",
        "                    pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfKB5IVu1IQE"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "746Bf9Ie1Kh8"
      },
      "outputs": [],
      "source": [
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBElCwwy5O1V"
      },
      "source": [
        "### GPU Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0lGIgp_1wvS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiaX1swq2KHd"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5_jzZVY5dth"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIzNAfyq5ii_"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFgEc7yt5jo0"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg5MCtmY5k4_"
      },
      "outputs": [],
      "source": [
        "img.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoQLfWa55mbH"
      },
      "outputs": [],
      "source": [
        "img_gpu = to_device(img, device)\n",
        "img_gpu.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGETIFyW5nwZ"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UncMNSft5vds"
      },
      "source": [
        "### Model and training utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DOPkiB55o5Z"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        \"calculate loss for a batch of training data\"\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        \"calculate loss & accuracy for a batch of validation data\"\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9p15ko372VU"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    \"\"\"Evaluates the model's performance on the validation set\"\"\"\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM0UCcRQ76k7"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKum4Zvv78S_"
      },
      "outputs": [],
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        # Input: 128 x 3 x 64 x 64\n",
        "        self.conv1 = conv_block(in_channels, 64) # 128 x 64 x 64 x 64\n",
        "        self.conv2 = conv_block(64, 128, pool=True) # 128 x 128 x 32 x 32\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), # 128 x 128 x 32 x 32\n",
        "                                  conv_block(128, 128)) # 128 x 128 x 32 x 32\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True) # 128 x 256 x 16 x 16\n",
        "        self.conv4 = conv_block(256, 512, pool=True) # 128 x 512 x 8 x 8 \n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), # 128 x 512 x 8 x 8 \n",
        "                                  conv_block(512, 512)) # 128 x 512 x 8 x 8 \n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), # 128 x 512 x 1 x 1 \n",
        "                                        nn.Flatten(), # 128 x 512\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrwv9L4L8BYZ"
      },
      "outputs": [],
      "source": [
        "model = to_device(ResNet9(3, len(dataset.classes)), device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD9lFCUR8FbM"
      },
      "outputs": [],
      "source": [
        "model.conv1[0].weight.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGgEjI__8nL7"
      },
      "outputs": [],
      "source": [
        "jovian.commit(project='deep-learning-project-live')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxemb46W_EUr"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "for batch in train_dl:\n",
        "    images, labels = batch\n",
        "    print('images.shape', images.shape)\n",
        "    print('images.device', images.device)\n",
        "    preds = model(images)\n",
        "    print('preds.shape', preds.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5v8LeLU_KRy"
      },
      "outputs": [],
      "source": [
        " jovian.commit(project = \"deep-learning-proect-live\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCuK2f8dwVIl"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7-Llp5VGwZ7P",
        "outputId": "3a972e68-54b3-4515-c070-67e5f5420bc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'val_acc': 0.1941489279270172, 'val_loss': 1.6095080375671387}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history = [evaluate(model, valid_dl)]\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os8jQqQkwcTM"
      },
      "outputs": [],
      "source": [
        "history += fit(5, 0.001, model, train_dl, valid_dl, torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqD1ETc3wgmV"
      },
      "outputs": [],
      "source": [
        "history += fit(5, 0.001, model, train_dl, valid_dl, torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3rOfGbowiq8"
      },
      "outputs": [],
      "source": [
        "history += fit(5, 0.0001, model, train_dl, valid_dl, torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzEU6p-NwkJQ"
      },
      "outputs": [],
      "source": [
        "history += fit(5, 0.0001, model, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy9v4aRiwmS8"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6qbgJz1wpGb"
      },
      "outputs": [],
      "source": [
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpztVDYKwqzl"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHyYicTsyK5x"
      },
      "outputs": [],
      "source": [
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4U4mVwYZFB"
      },
      "source": [
        "### Record the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldqhCjNcYYFo"
      },
      "outputs": [],
      "source": [
        "history[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD-RW8VuYdXm"
      },
      "outputs": [],
      "source": [
        "jovian.reset()\n",
        "jovian.log_dataset(image_size=64)\n",
        "jovian.log_hyperparams(batch_size=128, \n",
        "                       arch='ResNet9', \n",
        "                       epochs=[5, 5, 5, 5], \n",
        "                       lrs=[0.001, 0.001, 1e-4, 1e-4],\n",
        "                       opt=['Adam', 'Adam', 'Adam', 'SGD'])\n",
        "jovian.log_metrics(train_loss=history[-1]['train_loss'],\n",
        "                   val_acc=history[-1]['val_acc'],\n",
        "                   val_loss=history[-1]['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K97rKmsYfVI"
      },
      "outputs": [],
      "source": [
        "jovian.commit(project='deep-learning-project-live')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPEo1LSoYibr"
      },
      "source": [
        "### Test with Individual Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl_7k_3sYhAR"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model, classes):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lUgdX9zYnZO"
      },
      "outputs": [],
      "source": [
        "def show_image_prediction(img, label):\n",
        "    plt.imshow(img.permute((1, 2, 0)))\n",
        "    pred = predict_image(img, model, dataset.classes)\n",
        "    print('Target:', dataset.classes[label])\n",
        "    print('Prediction:', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcJ5ylbJYolF"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*valid_ds[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk7DKvfwYqFU"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*valid_ds[300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVD9Q65kYrP_"
      },
      "outputs": [],
      "source": [
        "show_image_prediction(*valid_ds[12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpwk3yxWYshn"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'flowers-resnet9.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i23l4zH6YuM4"
      },
      "outputs": [],
      "source": [
        "jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQajlASNYvey"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deep-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}